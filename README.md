---

# 第一部分｜基础与大模型原理（1–6）

---

## 1. 请你简要介绍 Transformer 的 Self-Attention 机制

**考察点**：是否真正理解 Attention，而不是背公式

**一句话回答**：
Self-Attention 通过计算序列内部任意位置之间的相关性，使模型在一次前向中建模长距离依赖。

**展开要点**：

* 对输入做线性映射得到 Q、K、V
* 权重 = softmax(QKᵀ / √d_k)
* 加权求和得到新的表示
* 多头 Attention 让模型在不同子空间关注不同关系
* 相比 RNN：并行、高效、长依赖稳定

---

## 2. 为什么 Transformer 比 RNN/LSTM 更适合大模型？

**考察点**：模型结构选择的本质原因

**一句话回答**：
因为 Transformer 可以并行计算并稳定建模长距离依赖，适合大规模数据与参数扩展。

**展开要点**：

* RNN 依赖时间步递归，难并行
* 长序列下梯度衰减/爆炸
* Transformer 计算路径短（O(1) 距离）
* 更适合 GPU/TPU 与分布式训练

---

## 3. 解释 KV Cache 的作用与原理

**考察点**：是否理解推理阶段的性能优化

**一句话回答**：
KV Cache 通过缓存历史 token 的 Key 和 Value，避免在自回归生成时重复计算 Attention。

**展开要点**：

* 仅对新 token 计算 Q
* 历史 K/V 直接复用
* 时间复杂度由 O(n²) → O(n)（解码阶段）
* 是 LLM 推理加速的核心手段之一

---

## 4. 解释 Temperature、Top-k、Top-p 的区别

**考察点**：对生成策略的理解

**一句话回答**：
它们控制模型输出分布的随机性与多样性。

**展开要点**：

* Temperature：缩放 logits，控制“敢不敢冒险”
* Top-k：只从概率最高的 k 个 token 中采样
* Top-p（nucleus）：选累计概率 ≥ p 的最小集合
* 工程实践：Top-p 更稳定，Top-k 更可控

---

## 5. 什么是 Hallucination？为什么会发生？

**考察点**：LLM 的根本缺陷理解

**一句话回答**：
Hallucination 是模型生成看似合理但事实错误的内容，源于训练目标与事实一致性不一致。

**展开要点**：

* 自回归目标最大化似然，而非事实正确性
* 训练数据噪声与分布偏移
* 上下文不足或超出知识边界
* 无“外部校验机制”

---

## 6. 常见减少 Hallucination 的工程方法有哪些？

**考察点**：是否具备工程视角

**一句话回答**：
通过检索增强、工具调用与结果校验来约束模型自由生成。

**展开要点**：

* RAG：引入外部知识
* Tool Calling：把事实查询交给系统
* Agent + Critic：自我检查
* 输出置信度或引用来源
* 结构化输出（JSON schema）

---

# 第二部分｜RAG 与 Agent（7–12）

---

## 7. 什么是 RAG？它解决了什么问题？

**考察点**：基础 LLM 应用能力

**一句话回答**：
RAG 通过在生成前检索外部文档，为模型提供实时、可更新的知识。

**展开要点**：

* 文档向量化 → 检索 → 拼接到 prompt
* 减少幻觉、增强时效性
* 常用于问答、文档分析
* 本质是“信息增强”

---

## 8. RAG 和 Agent 的核心区别是什么？

**考察点**：是否真正理解 Agent

**一句话回答**：
RAG 是被动提供信息，而 Agent 能主动规划、决策并调用工具。

**展开要点**：

* RAG：单轮/少轮，固定流程
* Agent：Plan → Act → Observe → Reflect
* Agent 可以把 RAG 当作一个工具
* Agent 适合复杂任务（多步骤）

---

## 9. 你如何设计一个典型的 Agent 架构？

**考察点**：系统设计能力

**一句话回答**：
我会拆分为 Planner、Executor、Memory 和 Critic 四个模块。

**展开要点**：

* Planner：任务分解、输出结构化计划
* Executor：调用工具执行子任务
* Memory：短期上下文 + 长期知识
* Critic：审查结果、触发重试
* 模块间通过 JSON schema 通信

---

## 10. Planner 和 Executor 如何解耦？

**考察点**：工程抽象能力

**一句话回答**：
通过明确的任务描述协议与输入输出 schema。

**展开要点**：

* Planner 输出结构化 plan（JSON）
* Executor 不理解语义，只执行 action
* 易于替换 Planner 策略（规则 / LLM）
* 有利于测试与扩展

---

## 11. 多 Agent 协作时会遇到哪些问题？

**考察点**：是否做过真实项目

**一句话回答**：
主要问题是通信成本、冲突决策和错误累积。

**展开要点**：

* Agent 目标不一致
* 上下文爆炸
* 延迟和成本上升
* 需要仲裁者（Critic / Controller）

---

## 12. 你如何评估一个 Agent 系统的效果？

**考察点**：评估意识

**一句话回答**：
我会从任务成功率、步骤合理性与成本三个维度评估。

**展开要点**：

* End-to-end success rate
* 每步执行是否合理（人工/规则）
* Token 成本、响应时间
* 对失败案例进行分析

---

# 第三部分｜工程化与系统设计（13–17）

---

## 13. 如何把一个传统模型（如作物模型）接入 Agent？

**考察点**：你最大的优势点

**一句话回答**：
把模型封装为标准化工具接口，由 Agent 通过参数调用。

**展开要点**：

* HTTP / gRPC / Python function
* 定义输入输出 schema
* 保证确定性与可重复
* 加缓存与并行执行

---

## 14. 如果 Agent 调用工具失败，你如何处理？

**考察点**：鲁棒性设计

**一句话回答**：
通过异常捕获、重试策略与回退方案。

**展开要点**：

* try/except + timeout
* exponential backoff
* fallback 到简化工具
* 记录失败到 Memory

---

## 15. 如何设计一个低延迟的 Agent 服务？

**考察点**：系统思维

**一句话回答**：
通过异步执行、批处理与缓存来优化。

**展开要点**：

* async IO / worker pool
* 批量 embedding / 推理
* KV Cache、结果缓存
* 拆分慢任务为异步

---

## 16. Docker 在你项目中的作用是什么？

**考察点**：工程素养

**一句话回答**：
保证环境一致性和可复现部署。

**展开要点**：

* 固定依赖版本
* 一键启动 demo
* 面试官可本地复现
* 为云部署做准备

---

## 17. 如何记录 Agent 的推理过程以便调试？

**考察点**：可维护性

**一句话回答**：
我会记录每一步的输入、输出与决策日志。

**展开要点**：

* 结构化日志（JSON）
* 每个 task 的时间戳
* 保存 prompt 与 response
* 用于回放与评估

---

# 第四部分｜综合能力与背景迁移（18–20）

---

## 18. 你不是纯 CS 出身，优势和劣势是什么？

**考察点**：自我认知

**一句话回答**：
劣势是缺少大规模模型训练经验，优势是复杂系统建模与工程落地能力。

**展开要点**：

* 农业模型本质是高维非线性系统
* 与 Agent 中的状态空间类似
* 我更擅长把模型变成可用系统

---

## 19. 如果让你参与 Kimi 的 Agent 产品，你能带来什么？

**考察点**：岗位匹配度

**一句话回答**：
我能把复杂专业场景抽象为可复用的 Agent 工具链。

**展开要点**：

* 工具接口设计
* 任务分解逻辑
* 可靠性与评估
* 面向真实用户的工程意识

---

## 20. 你未来 1–3 年的技术规划？

**考察点**：稳定性与成长性

**一句话回答**：
短期精进 Agent 系统工程，中期深入模型推理与效率优化。

**展开要点**：

* 1 年：Agent/RAG 工程专家
* 2 年：推理优化、系统规模化
* 3 年：参与模型能力设计或技术负责人

---
